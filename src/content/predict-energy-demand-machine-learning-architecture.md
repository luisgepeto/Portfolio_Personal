---
title: "Predicting energy demand: A machine learning architecture"
date: "2021-06-07"
draft: false
path: "/blog/predict-energy-demand-machine-learning-architecture"
tags: ["Azure", "*Azure ML Studi*o", "Machine Learning", ".NET"]
---

![*Azure ML Studio* Logo](/../images/azure-ml-studio-logo.png)

Machine Learning (ML) in the age of cloud computing has become ubiquitous. Many of the ML resources on the net go over the concepts of training, or theory behind the algorithms. This is vital if you plan to create a succesfull ML model. 

However, as engineers it is also crucial to put the results generated by our machine learning model at the hands of our users. For that we need a scalable and reliable architecture that can be reused across many products. This post will go over a sample custom architecture that might fit your needs.

# The requirement
The purpose of this architecture is to create a product that enables the Operation and Maintenance (O&M) personnel of a manufacturing plant to know how the energy demand of a chilled water HVAC will behave in the near future (~ 15 days). This will allow the team to plan operational changes that can result in energy savings.

After a brainstorming session with the stakeholders, the following requirements needed to be met by the architecture to meet the MVP:
1. *Predict the energy demand of a chilled water HVAC system at any point in the near future (15 days).*
2. *Present the predicted data to two types of stakeholders:*
    * **_Business stakeholders_** _need to access the data in a user friendly format, i.e. Excel or Microsoft Power BI, to make decisions based on the predicted energy cost._
    * **_Technical stakeholders_** _need to integrate the prediction to their proprietary systems, i.e. Building Management Systems (BMS), to make operational changes that can result in energy savings._
3. *Have the ability to improve the ML model as the independent variables on which the model was trained evolve through time.*
4. *Have the ability to extend the architecture to predict other O&M related data points as the product grows.*

# The architecture
This is an overview of the proposed architecture. I will go over each of its components and their role, as well as give a brief description of why each of the Azure resources used was chosen.

![Diagram depicting ML architecture](/../images/ml-architecture-diagram.png)

# The components

## ML Engine
![ML Engine](/../images/ml-architecture-ml-engine.png)
The ML Engine is the enabler of our architecture. *Azure ML Studio* was chosen to be used to create and train the models since it is a very powerful tool with a low barrier of entry which enables analytics through Jupyter notebooks and has a vast collection of ML algorithms to choose from.

*Azure ML Studio* allows us to expose an API that will be consumed by the prediction workflows, and also enables to retrain and redeploy it when needed. Therefore, it is possible to iterate over it as the independent variables (weather data and space occupation) change over time. This helps to meet requirements *(1)* and *(3)*.

## Prediction trigger
![Prediction trigger](/../images/ml-architecture-prediction-trigger.png)
A way of regulary triggering the prediction job is needed. The trigger can either be a scheduled-based schedule to keep the prediction updated, or any other business rule, e.g. whenever a business user books a meeting room that will change the space occupation.

For this purpose, an *Azure Logic App* will be used for every data point. If the business rules to trigger the prediction are updated (or new ones are required), a new *Logic Apps* can be created very quickly through the *Azure Portal*. This helps to meet requirement *(4)*.

## Prediction processing
![Prediction processing](/../images/ml-architecture-prediction-processing.png)
The actual creation of a data point prediction happens through a request to the *Azure ML Studio* API. However, because each data point may require information on independent variables retrieved from other sources - such as the latest weather prediction, or calculating the space occupation - a way to easily coordinate dependencies is needed. A *Logic App* provides the best way to understand how a certain data point is predicted.

As more data point predictions are added to the product, we can add the corresponding trigger and prediction workflow as a new *Logic App*, meeting requirement *(4)*.

## Prediction caching
![Prediction caching](/../images/ml-architecture-prediction-caching.png)

The purpose behind having a caching component multiple. This allows to limit the number of callls to our ML API, its dependent services and to minimize the number of times that the *Azure Logic Apps* run.

Using an *Azure Function* alongside with *Azure Storage Tables* to persist the cached data, allows to further decrease the cost while keeping the entire infrastructure functional and ready to respond to new requests instantaneously. This way the most complex parts of the architecture only run when needed and not every time an external consumer requests the result of a prediction. 

Another resource that appears as part of the prediction caching component is the *Azure Key Vault*. Using a key vault to store secrets and configuration values has a lot of advantages that will be covered in future posts.

## Customer facing API
![Customer facing API](/../images/ml-architecture-customer-facing-api.png)
All of the previous architecture components were 
inner-facing, meaning that they will only be interacting with each other within the infrastructure. In order to provide a way for our stakeholders to view the results of the energy demand prediction we need to give them an HTTP endpoint over which it can be specified which data points prediction each stakeholders has access to. 

This can be achieved through the use of *Azure API Management*, which allows to bundle APIs into products and set up policies to our stakeholders such as usage quotas and user management.

This API can be consumed by most data manipulation software such as Excel or Power BI. Also because it is exposed as an HTTP endpoint, it can be implemented on any webpage or called from within a proprietary BMS system, fulfilling requirement *(2)*.


# The implementation
The resulting implementation of the architecture is depicted in the following diagram. Since the energy demand for the chilled water HVAC system depends on both the weather forecast data and the occupation schedule of the different meeting rooms, the APIs that expose this data need to be queried by the *Azure Logic App* that controlls the prediction processing for the data point. 

![Diagram with implemented ML architecture](/../images/ml-architecture-diagram-implementation.png)

For this specific implementation, a report was generated in Excel where the API `GET GetLastestPrediction` endpoint was called through VBA code and where the specific API key on our API product for the end user was passed as a Header. This the generated report for one of the test runs:

![Energy demand chart prediction](/../images/ml-architecture-excel.png)

In case you wonder how the Azure ML training interface looks like, it is pretty simple (although the training process itself was fairly time consuming). 

![Azure ML Studio Model in training](/../images/azure-ml-studio-sample.png)

# Final thoughts and next steps
Some of the next steps that are worth exploring are how the architecture can accomodate a retraining scenario. Currently the retraining would need to be done manually, however we could integrate this as part of a regular workflow since *Azure ML Studio* exposes an API for this purpose. This could also imply some considerations such as API versioning in case that we introduced breaking changes and needed to support older consumers. 

Sadly enough, although this architecture did come to life as a proof of concept, it was never released as a full product due to technical limitations on the stakeholder side having to do with a lack of monitoring of the energy demand to continue moving forward with the ML model improvement.

# About the resources
If you wish to learn more about the Azure resources used in this architecture, feel free to dive into their documentation:

## [Azure Machine Learning Studio (classic)](https://studio.azureml.net/)

## [Azure Logic Apps](https://azure.microsoft.com/en-us/services/logic-apps/)

## [Azure API Management](https://azure.microsoft.com/en-us/services/api-management/)

## [Azure Functions](https://azure.microsoft.com/en-us/services/functions/)

## [Azure Key Vault](https://azure.microsoft.com/en-us/services/key-vault/)

## [Azure Storage](https://azure.microsoft.com/en-us/product-categories/storage/)